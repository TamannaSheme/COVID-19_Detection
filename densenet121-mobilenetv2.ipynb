{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nimport pandas as pd\nimport numpy as np\n\ncnf, dth, rec, act = '#393e46', '#ff2e63', '#21bf73', '#fe9801' \n\n\nfull_grouped = pd.read_csv('../input/corona-virus-report/full_grouped.csv')\nfull_grouped['Date'] = pd.to_datetime(full_grouped['Date'])\n\n\nday_wise = pd.read_csv('../input/corona-virus-report/day_wise.csv')\nday_wise['Date'] = pd.to_datetime(day_wise['Date'])\n\n\ncountry_wise = pd.read_csv('../input/corona-virus-report/country_wise_latest.csv')\ncountry_wise = country_wise.replace('', np.nan).fillna(0)\n# country_wise.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T13:06:12.373107Z","iopub.execute_input":"2022-02-03T13:06:12.373346Z","iopub.status.idle":"2022-02-03T13:06:13.267295Z","shell.execute_reply.started":"2022-02-03T13:06:12.373320Z","shell.execute_reply":"2022-02-03T13:06:13.266526Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"worldometer_data = pd.read_csv('../input/worldometer-stats/wworldometer.csv')\nworldometer_data = worldometer_data.replace('', np.nan).fillna(0)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T13:06:13.270072Z","iopub.execute_input":"2022-02-03T13:06:13.270618Z","iopub.status.idle":"2022-02-03T13:06:13.285073Z","shell.execute_reply.started":"2022-02-03T13:06:13.270574Z","shell.execute_reply":"2022-02-03T13:06:13.284314Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"temp = day_wise[['Date','Deaths', 'Recovered', 'Active']].tail(1)\ntemp = temp.melt(id_vars=\"Date\", value_vars=['Active', 'Deaths', 'Recovered'])\nfig = px.treemap(temp, path=[\"variable\"], values=\"value\", height=225, \n                 color_discrete_sequence=[act, rec, dth])\nfig.data[0].textinfo = 'label+text+value'","metadata":{"execution":{"iopub.status.busy":"2022-02-03T13:06:13.288391Z","iopub.execute_input":"2022-02-03T13:06:13.288658Z","iopub.status.idle":"2022-02-03T13:06:14.072118Z","shell.execute_reply.started":"2022-02-03T13:06:13.288634Z","shell.execute_reply":"2022-02-03T13:06:14.071346Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def plot_map(df, col, pal):\n    df = df[df[col]>0]\n    fig = px.choropleth(df, locations=\"Country/Region\", locationmode='country names', \n                  color=col, hover_name=\"Country/Region\", \n                  title=col, hover_data=[col], color_continuous_scale=pal)\n    fig.show()\nplot_map(country_wise, 'Confirmed', 'matter')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T13:06:14.074623Z","iopub.execute_input":"2022-02-03T13:06:14.075124Z","iopub.status.idle":"2022-02-03T13:06:14.207863Z","shell.execute_reply.started":"2022-02-03T13:06:14.075083Z","shell.execute_reply":"2022-02-03T13:06:14.207166Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Load the libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\nimport numpy as np # linear algebra\n # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import  Input, Conv2D, MaxPooling2D,GlobalMaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Activation, MaxPool2D, AvgPool2D, Dropout, Conv1D, MaxPooling1D\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.applications import DenseNet121, VGG19, ResNet50\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom IPython.display import display, Image\nimport matplotlib.pyplot as mpimg\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.utils import shuffle\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-03T13:06:14.211628Z","iopub.execute_input":"2022-02-03T13:06:14.211888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Updates\nVERSION-16\n1. Images displayed with labels and Histogram plots\n2. CNN model developed with accuracy and loss plot\n3. initiation of callbacks for the above models\n4. DenseNet121 simplified \n5. Mobilenet_V2\n6. Predictions ","metadata":{}},{"cell_type":"markdown","source":"# 1. Loading Datasets","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv')\nvalid_df = pd.read_csv('../input/coronahack-chest-xraydataset/Chest_xray_Corona_dataset_Summary.csv')\n\nprint('The training dataset has rows : ', format(train_df.shape[0]))\nprint('The training dataset has cols : ', format(train_df.shape[1]))","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Missing Values","metadata":{}},{"cell_type":"code","source":"missing_vals = train_df.isnull().sum()\nmissing_vals.plot(kind = 'bar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.dropna(how = 'all')\ntrain_df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train_df[train_df['Dataset_type'] == 'TRAIN']\ntest_data = train_df[train_df['Dataset_type'] == 'TEST']\nassert train_data.shape[0] + test_data.shape[0] == train_df.shape[0]\nprint(f\"Shape of train data : {train_data.shape}\")\nprint(f\"Shape of test data : {test_data.shape}\")\ntest_data.sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's fill the missing values with 'unknown'","metadata":{}},{"cell_type":"code","source":"train_fill = train_data.fillna('unknown')\ntest_fill = test_data.fillna('unknown')\ndisplay(train_fill.head(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Visualization of Unknown Data","metadata":{}},{"cell_type":"code","source":"# Count plot for 3 attributes with unknown variable addition\ntargets = ['Label', 'Label_2_Virus_category', 'Label_1_Virus_category']\nfig, ax = plt.subplots(2, 2, figsize=(20, 10))\nsns.countplot(x=targets[0], data=train_fill, ax=ax[0, 0])\nsns.countplot(x=targets[1], data=train_fill, ax=ax[0, 1])\nsns.countplot(x=targets[2], data=train_fill, ax=ax[1, 0])\nplt. savefig('100dpi.png', dpi=100)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Display Images","metadata":{}},{"cell_type":"code","source":"test_img_dir = '/kaggle/input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test'\ntrain_img_dir = '/kaggle/input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train'\n\nassert os.path.isdir(test_img_dir) == True\nassert os.path.isdir(train_img_dir) == True\n\nsample_train_images = list(os.walk(train_img_dir))[0][2][:8]\nsample_train_images = list(map(lambda x: os.path.join(train_img_dir, x), sample_train_images))\n\nsample_test_images = list(os.walk(test_img_dir))[0][2][:8]\nsample_test_images = list(map(lambda x: os.path.join(test_img_dir, x), sample_test_images))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nplt.figure(figsize = (17,17))\nfor iterator, filename in enumerate(sample_train_images):\n    image = Image.open(filename)\n    plt.subplot(4,2,iterator+1)\n    plt.imshow(image)\n\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Displaying test images","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (17,17))\nfor iterator, filename in enumerate(sample_test_images):\n    image = Image.open(filename)\n    plt.subplot(4,2,iterator+1)\n    plt.imshow(image)\n\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.1 Histogram analysis of Images","metadata":{}},{"cell_type":"markdown","source":"**For COVID-19 cases**","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(4, 2, figsize=(17, 17))\n\n\ncovid_path = train_data[train_data['Label_2_Virus_category']=='COVID-19']['X_ray_image_name'].values\n\nsample_covid_path = covid_path[:4]\nsample_covid_path = list(map(lambda x: os.path.join(train_img_dir, x), sample_covid_path))\n\nfor row, file in enumerate(sample_covid_path):\n    image = plt.imread(file)\n    ax[row, 0].imshow(image)\n    ax[row, 1].hist(image.ravel(), 256, [0,256])\n    ax[row, 0].axis('off')\n    if row == 0:\n        ax[row, 0].set_title('Images')\n        ax[row, 1].set_title('Histograms')\nfig.suptitle('Label 2 Virus Category = COVID-19', size=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Normal Histogram images**","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(4, 2, figsize=(17, 17))\n\n\nnormal_path = train_data[train_data['Label']=='Normal']['X_ray_image_name'].values\n\nsample_normal_path = normal_path[:4]\nsample_normal_path = list(map(lambda x: os.path.join(train_img_dir, x), sample_normal_path))\n\nfor row, file in enumerate(sample_normal_path):\n    image = plt.imread(file)\n    ax[row, 0].imshow(image)\n    ax[row, 1].hist(image.ravel(), 256, [0,256])\n    ax[row, 0].axis('off')\n    if row == 0:\n        ax[row, 0].set_title('Images')\n        ax[row, 1].set_title('Histograms')\nfig.suptitle('Label = NORMAL', size=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Image Augmentation","metadata":{}},{"cell_type":"code","source":"final_train_data = train_data[(train_data['Label'] == 'Normal') | \n                              ((train_data['Label'] == 'Pnemonia') & (train_data['Label_2_Virus_category'] == 'COVID-19'))]\n\n\n# Create a target attribute where value = positive if 'Pnemonia + COVID-19' or value = negative if 'Normal'\nfinal_train_data['target'] = ['negative' if holder == 'Normal' else 'positive' for holder in final_train_data['Label']]\n\nfinal_train_data = shuffle(final_train_data, random_state=1)\n\nfinal_validation_data = final_train_data.iloc[1000:, :]\nfinal_train_data = final_train_data.iloc[:1000, :]\n\nprint(f\"Final train data shape : {final_train_data.shape}\")\nfinal_train_data.sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image_generator = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=90,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    horizontal_flip=True,\n    zoom_range=0.5,\n)\n\ntest_image_generator = ImageDataGenerator(\n    rescale=1./255\n)\n\ntrain_generator = train_image_generator.flow_from_dataframe(\n    dataframe=final_train_data,\n    directory=train_img_dir,\n    x_col='X_ray_image_name',\n    y_col='target',\n    target_size=(224, 224),\n    batch_size=16,\n    seed=2020,\n    shuffle=True,\n    class_mode='binary'\n)\n\nvalidation_generator = train_image_generator.flow_from_dataframe(\n    dataframe=final_validation_data,\n    directory=train_img_dir,\n    x_col='X_ray_image_name',\n    y_col='target',\n    target_size=(224, 224),\n    batch_size=16,\n    seed=2020,\n    shuffle=True,\n    class_mode='binary'\n)\n\ntest_generator = test_image_generator.flow_from_dataframe(\n    dataframe=test_data,\n    directory=test_img_dir,\n    x_col='X_ray_image_name',\n    target_size=(224, 224),\n    shuffle=False,\n    batch_size=16,\n    class_mode=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Model Development","metadata":{}},{"cell_type":"code","source":"IMG_W = 224\nIMG_H = 224\nCHANNELS = 3\n\nINPUT_SHAPE = (IMG_W, IMG_H, CHANNELS)\nNB_CLASSES = 2\nEPOCHS = 50\nBATCH_SIZE = 6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6.1 Convolutional Neural Network","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(250,(3,3)))\nmodel.add(Activation(\"relu\"))\n  \nmodel.add(Conv2D(128,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(AvgPool2D(2,2))\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(AvgPool2D(2,2))\n\nmodel.add(Conv2D(256,(2,2)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(2,2))\n    \nmodel.add(Flatten())\nmodel.add(Dense(32))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1))\nmodel.add(Activation(\"sigmoid\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('accuracy')>0.9325):\n            print(\"\\nReached 94.25% accuracy so cancelling training!\")\n            self.model.stop_training = True\ncallbacks = myCallback()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nhistory = model.fit(train_generator,\n                              steps_per_epoch = len(train_generator),\n                              validation_data=validation_generator,\n                              epochs=20,\n                              validation_steps=len(validation_generator),\n                              callbacks = [callbacks]\n                                     )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plots to estimate loss and accuracy**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(17,17))\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'], label='Loss')\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['accuracy'], label='Accuracy')\nplt.legend()\nplt.title('Train - Accuracy')\n\nplt.legend()\nplt.title('Metrics estimations')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6.2 Transfer Learning","metadata":{}},{"cell_type":"markdown","source":"# DenseNet121","metadata":{}},{"cell_type":"code","source":"dense_model = Sequential()\ndense_model.add(DenseNet121(include_top=False, pooling = 'avg', weights='imagenet',input_shape=(224, 224, 3), classes=2))\ndense_model.add(Dense(512, activation='relu'))\ndense_model.add(Dense(128, activation='relu'))\ndense_model.add(Dense(64, activation='relu'))\ndense_model.add(Dense(1, activation='sigmoid'))\ndense_model.layers[0].trainable = False\ndense_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dense_history = dense_model.fit_generator(train_generator,\n                                          steps_per_epoch = len(train_generator),\n                                          validation_data=validation_generator,\n                                          epochs=20,\n                                          validation_steps=len(validation_generator),\n                                          callbacks = [callbacks]\n                                             )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(17,17))\n\nplt.subplot(2, 2, 1)\nplt.plot(dense_history.history['loss'], label='Loss')\nplt.plot(dense_history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(dense_history.history['accuracy'], label='Accuracy')\nplt.plot(dense_history.history['val_accuracy'], label='Validation Accuracy')\n\nplt.legend()\nplt.title('Train - Accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MobileNetV2","metadata":{}},{"cell_type":"code","source":"mob_model = Sequential()\nmob_model.add(tf.keras.applications.MobileNetV2(include_top=False, pooling = 'avg', weights='imagenet',input_shape=(224, 224, 3), classes=2))\nmob_model.add(Dense(32, activation='relu'))\nmob_model.add(Dense(1, activation='sigmoid'))\nmob_model.layers[0].trainable = False\nmob_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mob_history = mob_model.fit_generator(train_generator,\n                              steps_per_epoch = len(train_generator),\n                              validation_data=validation_generator,\n                              epochs=20,\n                              validation_steps=len(validation_generator),\n                              callbacks = [callbacks]\n                                     )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(17,17))\n\nplt.subplot(2, 2, 1)\nplt.plot(mob_history.history['loss'], label='Loss')\nplt.plot(mob_history.history['loss'], label='Validation Loss')\n\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(mob_history.history['accuracy'], label='Accuracy')\nplt.plot(mob_history.history['val_accuracy'], label='Validation Accuracy')\n\n\nplt.legend()\nplt.title('Train - Accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(validation_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dense_model.predict(validation_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mob_model.predict(validation_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = validation_generator.classes\nprint('Cases summary of the models : \\n{}'.format(label))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Normal:- 0, COVID:- 1***","metadata":{}},{"cell_type":"markdown","source":"# CNN predictions","metadata":{}},{"cell_type":"code","source":"pred= model.predict(validation_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('CNN Model Predictions : \\n{}'.format(predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\n\ncf_matrix = confusion_matrix(predicted_class_indices,label)\ncf_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exp_series = pd.Series(label)\npred_series = pd.Series(predicted_class_indices)\npd.crosstab(exp_series, pred_series, rownames=['Actual'], colnames=['Predicted'],margins=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nmatrix_index = [\"Normal\", \"Covid\"]\n\npreds = model.predict(validation_generator)\nclasspreds = np.argmax(preds, axis=1) # predicted classes \n#y_testclass = np.argmax(valida, axis=1) # true classes\n\ncm = confusion_matrix(predicted_class_indices,label)\nprint(classification_report(predicted_class_indices,label, target_names=matrix_index))\n\n# Get percentage value for each element of the matrix\ncm_sum = np.sum(cm, axis=1, keepdims=True)\ncm_perc = cm / cm_sum.astype(float) * 100\nannot = np.empty_like(cm).astype(str)\nnrows, ncols = cm.shape\nfor i in range(nrows):\n    for j in range(ncols):\n        c = cm[i, j]\n        p = cm_perc[i, j]\n        if i == j:\n            s = cm_sum[i]\n            annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n        elif c == 0:\n            annot[i, j] = ''\n        else:\n            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n\n\n# Display confusion matrix \ndf_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nfig, ax = plt.subplots(figsize=(10,7))\nsns.heatmap(df_cm, annot=annot, fmt='')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DenseNet predictions","metadata":{}},{"cell_type":"code","source":"pred= dense_model.predict(validation_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('DenseNet Model Predictions : \\n{}'.format(predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cf_matrix = confusion_matrix(predicted_class_indices,label)\ncf_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exp_series = pd.Series(label)\npred_series = pd.Series(predicted_class_indices)\npd.crosstab(exp_series, pred_series, rownames=['Actual'], colnames=['Predicted'],margins=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matrix_index = [\"Normal\", \"Covid\"]\n\npreds = dense_model.predict(validation_generator)\nclasspreds = np.argmax(preds, axis=1) # predicted classes \n#y_testclass = np.argmax(valida, axis=1) # true classes\n\ncm = confusion_matrix(predicted_class_indices,label)\nprint(classification_report(predicted_class_indices,label, target_names=matrix_index))\n\n# Get percentage value for each element of the matrix\ncm_sum = np.sum(cm, axis=1, keepdims=True)\ncm_perc = cm / cm_sum.astype(float) * 100\nannot = np.empty_like(cm).astype(str)\nnrows, ncols = cm.shape\nfor i in range(nrows):\n    for j in range(ncols):\n        c = cm[i, j]\n        p = cm_perc[i, j]\n        if i == j:\n            s = cm_sum[i]\n            annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n        elif c == 0:\n            annot[i, j] = ''\n        else:\n            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n\n\n# Display confusion matrix \ndf_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nfig, ax = plt.subplots(figsize=(10,7))\nsns.heatmap(df_cm, annot=annot, fmt='')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MobileNet predictions","metadata":{}},{"cell_type":"code","source":"pred= mob_model.predict(validation_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('MobileNet Model Predictions : \\n{}'.format(predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cf_matrix = confusion_matrix(predicted_class_indices,label)\ncf_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exp_series = pd.Series(label)\npred_series = pd.Series(predicted_class_indices)\npd.crosstab(exp_series, pred_series, rownames=['Actual'], colnames=['Predicted'],margins=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matrix_index = [\"Normal\", \"Covid\" ]\n\npreds = mob_model.predict(validation_generator)\nclasspreds = np.argmax(preds, axis=1) # predicted classes \n#y_testclass = np.argmax(valida, axis=1) # true classes\n\ncm = confusion_matrix(predicted_class_indices,label)\nprint(classification_report(predicted_class_indices,label, target_names=matrix_index))\n\n# Get percentage value for each element of the matrix\ncm_sum = np.sum(cm, axis=1, keepdims=True)\ncm_perc = cm / cm_sum.astype(float) * 100\nannot = np.empty_like(cm).astype(str)\nnrows, ncols = cm.shape\nfor i in range(nrows):\n    for j in range(ncols):\n        c = cm[i, j]\n        p = cm_perc[i, j]\n        if i == j:\n            s = cm_sum[i]\n            annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n        elif c == 0:\n            annot[i, j] = ''\n        else:\n            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n\n\n# Display confusion matrix \ndf_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nfig, ax = plt.subplots(figsize=(10,7))\nsns.heatmap(df_cm, annot=annot, fmt='')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}